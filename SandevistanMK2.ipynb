{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dace6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "import math \n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import date, timedelta \n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import time\n",
    "import smtplib\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db04003e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovo je x train:\n",
      "(254, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(254,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(144, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(144,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(254, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(254,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(184, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(184,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(257, 12, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(257,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(154, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(154,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(194, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(194,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(174, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(174,)\n",
      "ovo je y test:\n",
      "(0,)\n",
      "ovo je x train:\n",
      "(194, 15, 1)\n",
      "ovo x test:\n",
      "(0,)\n",
      "ovo je y train:\n",
      "(194,)\n",
      "ovo je y test:\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "import math \n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import date, timedelta \n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import time\n",
    "import smtplib\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "\n",
    "\n",
    "def ko():\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/BTCUSDT_Binance_futures_data_day.csv\", \"sandevistan/BTC.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/LTCUSDT_Binance_futures_data_day.csv\", \"sandevistan/LTC.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/LINKUSDT_Binance_futures_data_day.csv\", \"sandevistan/LINK.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/BNBUSDT_Binance_futures_data_day.csv\", \"sandevistan/BNB.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/XRPUSDT_Binance_futures_data_day.csv\", \"sandevistan/XRP.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/EOSUSDT_Binance_futures_data_day.csv\", \"sandevistan/EOS.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/TRXUSDT_Binance_futures_data_day.csv\", \"sandevistan/TRX.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/NEOUSDT_Binance_futures_data_day.csv\", \"sandevistan/NEO.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/XLMUSDT_Binance_futures_data_day.csv\", \"sandevistan/XLM.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_MATICUSDT_d.csv\", \"sandevistan/MATIC.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_SOLUSDT_d.csv\", \"sandevistan/SOL.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_EGLDUSDT_d.csv\", \"sandevistan/EGLD.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_DOTUSDT_d.csv\", \"sandevistan/DOT.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_DAOUSDT_d.csv\", \"sandevistan/DAO.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_CAKEUSDT_d.csv\", \"sandevistan/CAKE.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_AVAXUSDT_d.csv\", \"sandevistan/AVAX.csv\")\n",
    "    urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/Kucoin_ALGOUSDT_d.csv\", \"sandevistan/ALGO.csv\")\n",
    "\n",
    "    df2 = [0] * 17\n",
    "\n",
    "    df2[0]=pd.read_csv(\"sandevistan/BTC.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[1]=pd.read_csv(\"sandevistan/LTC.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[2]=pd.read_csv(\"sandevistan/LINK.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[3]=pd.read_csv(\"sandevistan/BNB.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[4]=pd.read_csv(\"sandevistan/XRP.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[5]=pd.read_csv(\"sandevistan/EOS.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[6]=pd.read_csv(\"sandevistan/TRX.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[7]=pd.read_csv(\"sandevistan/NEO.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[8]=pd.read_csv(\"sandevistan/XLM.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[9]=pd.read_csv(\"sandevistan/MATIC.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[10]=pd.read_csv(\"sandevistan/SOL.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[11]=pd.read_csv(\"sandevistan/EGLD.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[12]=pd.read_csv(\"sandevistan/DOT.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[13]=pd.read_csv(\"sandevistan/DAO.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[14]=pd.read_csv(\"sandevistan/CAKE.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[15]=pd.read_csv(\"sandevistan/AVAX.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "    df2[16]=pd.read_csv(\"sandevistan/ALGO.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def updatedprediction(df,epohe,neuroni,dflen,seq):\n",
    "        df1= df[0:dflen]\n",
    "        df1=df1[::-1]\n",
    "\n",
    "        train_df = df1.filter(['close'])\n",
    "        data_unscaled = train_df.values\n",
    "\n",
    "        mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        np_data = mmscaler.fit_transform(data_unscaled)\n",
    "        sequence_length = seq\n",
    "        predict_length = 1\n",
    "\n",
    "        index_Close = train_df.columns.get_loc(\"close\")\n",
    "\n",
    "        train_data_len = dflen-predict_length\n",
    "\n",
    "        train_data = np_data\n",
    "        test_data = np_data[train_data_len - sequence_length:,:]\n",
    "        test_data1 = np_data[dflen - sequence_length- predict_length:, :]\n",
    "\n",
    "        def partition_dataset(sequence_length, train_df):\n",
    "            x, y = [], []\n",
    "            data_len = train_df.shape[0]\n",
    "            for i in range(sequence_length, data_len-predict_length):\n",
    "                x.append((train_df[i-sequence_length:i,:])+(train_df[i+predict_length]))\n",
    "                y.append(train_df[i+predict_length, index_Close]) \n",
    "\n",
    "            x = np.array(x)\n",
    "            y = np.array(y)\n",
    "            return x, y\n",
    "\n",
    "        def particijazapredikciju(sequence_length, train_df):\n",
    "            x, y = [], []\n",
    "            data_len = train_df.shape[0]\n",
    "            for i in range(sequence_length, data_len):\n",
    "                x.append((train_df[i-sequence_length:i,:])+(train_df[i]))\n",
    "            x = np.array(x)\n",
    "            return x\n",
    "\n",
    "        x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "        x_test, y_test = partition_dataset(sequence_length, test_data)\n",
    "\n",
    "        print(\"ovo je x train:\")\n",
    "        print(x_train.shape)\n",
    "        print(\"ovo x test:\")\n",
    "        print(x_test.shape)\n",
    "        print(\"ovo je y train:\")\n",
    "        print(y_train.shape)\n",
    "        print(\"ovo je y test:\")\n",
    "        print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def makemodels():\n",
    "\n",
    "            neurons=sequence_length\n",
    "            model2 = Sequential()\n",
    "            model2.add(Bidirectional(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], 1))))\n",
    "            model2.add(Bidirectional(LSTM(neurons, return_sequences=False)))\n",
    "            model2.add(Dense(neuroni, activation='relu'))\n",
    "            model2.add(Dense(1))\n",
    "            model2.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "            return model2\n",
    "\n",
    "        model=makemodels()\n",
    "\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=15, epochs=epohe,verbose=0)\n",
    "\n",
    "        #y_pred_scaled = model.predict(x_test)\n",
    "        #y_pred = mmscaler.inverse_transform(y_pred_scaled)\n",
    "        #y_test_unscaled = mmscaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        #MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "        #print(f'Mean Absolute Percentage Error (MAPE): {np.round(MAPE, 2)} %')\n",
    "\n",
    "        prerad=particijazapredikciju(sequence_length,test_data1)\n",
    "\n",
    "\n",
    "        trupred= model.predict(prerad)\n",
    "\n",
    "\n",
    "        trupred1= mmscaler.inverse_transform(trupred)\n",
    "\n",
    "        pp = trupred1.tolist()\n",
    "\n",
    "        predval=[]\n",
    "\n",
    "        predval=predval+pp        \n",
    "\n",
    "        df55 = pd.DataFrame(data=(predval),columns=['Pred'])\n",
    "\n",
    "        return df55;\n",
    "\n",
    "\n",
    "    def prediction(df,epohe,dani,neuroni):\n",
    "        df1= df[0:165]\n",
    "        df1=df1[::-1]\n",
    "\n",
    "        train_df = df1.filter(['close'])\n",
    "        data_unscaled = train_df.values\n",
    "\n",
    "        train_data_length = 161\n",
    "\n",
    "        mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        np_data = mmscaler.fit_transform(data_unscaled)\n",
    "        sequence_length = 13\n",
    "        predict_length=1\n",
    "\n",
    "        index_Close = train_df.columns.get_loc(\"close\")\n",
    "        print(index_Close)\n",
    "\n",
    "        train_data_len = 161\n",
    "\n",
    "        train_data = np_data\n",
    "        test_data = np_data[train_data_len - sequence_length:, :]\n",
    "\n",
    "\n",
    "        def partition_dataset(sequence_length, train_df):\n",
    "            x, y = [], []\n",
    "            data_len = train_df.shape[0]\n",
    "            for i in range(sequence_length, data_len-predict_length):\n",
    "                x.append((train_df[i-sequence_length:i,:])+(train_df[i+predict_length]))\n",
    "                y.append(train_df[i+predict_length, index_Close]) \n",
    "\n",
    "            x = np.array(x)\n",
    "            y = np.array(y)\n",
    "            return x, y\n",
    "\n",
    "        x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "        x_test, y_test = partition_dataset(sequence_length, test_data)\n",
    "\n",
    "        print(x_train.shape, y_train.shape)\n",
    "        print(x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "        def makemodels():\n",
    "\n",
    "            neurons=sequence_length\n",
    "            model2 = Sequential()\n",
    "            model2.add(Bidirectional(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], 1))))\n",
    "            model2.add(Bidirectional(LSTM(neurons, return_sequences=False)))\n",
    "            model2.add(Dense(15, activation='relu'))\n",
    "            model2.add(Dense(1))\n",
    "            model2.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "            return model2\n",
    "\n",
    "        model=makemodels()\n",
    "\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=13, epochs=se,verbose=0)\n",
    "\n",
    "        y_pred_scaled = model.predict(x_test)\n",
    "        y_pred = mmscaler.inverse_transform(y_pred_scaled)\n",
    "        y_test_unscaled = mmscaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        MAE = mean_absolute_error(y_test_unscaled, y_pred)\n",
    "        print(f'Median Absolute Error (MAE): {np.round(MAE, 2)}')\n",
    "\n",
    "        MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "        print(f'Mean Absolute Percentage Error (MAPE): {np.round(MAPE, 2)} %')\n",
    "\n",
    "        MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled)) ) * 100\n",
    "        print(f'Median Absolute Percentage Error (MDAPE): {np.round(MDAPE, 2)} %')\n",
    "\n",
    "        y_pred = y_pred.tolist()\n",
    "\n",
    "        predval=[]\n",
    "\n",
    "        predval=predval+y_pred        \n",
    "\n",
    "        df55 = pd.DataFrame(data=(predval),columns=['Pred'])\n",
    "\n",
    "        return df55;\n",
    "\n",
    "    def kalkulator(predvidjeni,trenutni):\n",
    "        dfc=trenutni[0:1]\n",
    "\n",
    "        dfc['close']\n",
    "        total=sum(predvidjeni['Pred'])\n",
    "        average=total/len(predvidjeni)\n",
    "\n",
    "        odnosbtc= average/dfc['close']\n",
    "        odnosbtc= (average/dfc['close']-1)*100\n",
    "        return odnosbtc\n",
    "\n",
    "    thisdict = [0]*17\n",
    "\n",
    "    listaepoha=[130,100,130,160,100,130,130,130,130,130,150,130,100,130,130,130,130]\n",
    "    listaneurona=[26,30,15,26,15,12,15,15,15,15,15,15,15,15,15,15,15]\n",
    "    listadana=[270,170,160,270,200,270,170,170,170,170,170,170,170,170,210,190,210]\n",
    "    \n",
    "\n",
    "    for i in range(17):\n",
    "        dfka=df2[i][0:1]\n",
    "        if(i==5):\n",
    "            predvidjeni=updatedprediction(df2[i],listaepoha[i],listaneurona[i],listadana[i],12)\n",
    "        else:\n",
    "            predvidjeni=updatedprediction(df2[i],listaepoha[i],listaneurona[i],listadana[i],15)\n",
    "        odnos=kalkulator(predvidjeni,df2[i])\n",
    "        thisdict[i]={\n",
    "            \"Sign\": dfka['symbol'],\n",
    "            \"Profit\" : odnos\n",
    "        }\n",
    "\n",
    "\n",
    "        stringara=\"\"\n",
    "\n",
    "    for i in range(17):\n",
    "        isussveti=thisdict[i][\"Profit\"][0]\n",
    "        isussveti1=thisdict[i][\"Sign\"][0]\n",
    "\n",
    "        stringara += \"Kriptovaluta: \" + str(isussveti1)[0:3] + \" će u sledeca 2 dana da ima razliku od: \" +  str(isussveti)[0:5] +  \"\\n\" \n",
    "\n",
    "    email_address = \"xsimostt@gmail.com\"\n",
    "\n",
    "    email_password=\"frlqtrvjzdvgstkf\"\n",
    "\n",
    "        # create email\n",
    "    msg = EmailMessage()\n",
    "    msg['Subject'] = \"Black nigga tips\"\n",
    "    msg['From'] = email_address\n",
    "    msg['To'] = \"simkebiz@gmail.com,jasminmesic2@gmail.com,\"\n",
    "    msg.set_content(stringara)\n",
    "\n",
    "        # send email\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
    "        smtp.login(email_address, email_password)\n",
    "        smtp.send_message(msg)\n",
    "\n",
    "#while 1:\n",
    "   # now = datetime.now()\n",
    "    #if(now.hour==20 and now.minute==43):\n",
    "     #   ko()\n",
    "   # else:\n",
    "    #    time.sleep(59)\n",
    "    \n",
    "ko()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2befcd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 136.27\n",
      "Mean Absolute Percentage Error (MAPE): 0.83 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.78 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 6.94\n",
      "Mean Absolute Percentage Error (MAPE): 0.58 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.5 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 2.69\n",
      "Mean Absolute Percentage Error (MAPE): 3.53 %\n",
      "Median Absolute Percentage Error (MDAPE): 3.59 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 0.28\n",
      "Mean Absolute Percentage Error (MAPE): 3.91 %\n",
      "Median Absolute Percentage Error (MDAPE): 4.48 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 13.01\n",
      "Mean Absolute Percentage Error (MAPE): 4.24 %\n",
      "Median Absolute Percentage Error (MDAPE): 4.64 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 0.01\n",
      "Mean Absolute Percentage Error (MAPE): 2.66 %\n",
      "Median Absolute Percentage Error (MDAPE): 2.12 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 0.01\n",
      "Mean Absolute Percentage Error (MAPE): 1.6 %\n",
      "Median Absolute Percentage Error (MDAPE): 1.71 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 0.0\n",
      "Mean Absolute Percentage Error (MAPE): 0.61 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.68 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 0.17\n",
      "Mean Absolute Percentage Error (MAPE): 2.45 %\n",
      "Median Absolute Percentage Error (MDAPE): 2.58 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 0.18\n",
      "Mean Absolute Percentage Error (MAPE): 0.92 %\n",
      "Median Absolute Percentage Error (MDAPE): 1.12 %\n",
      "0\n",
      "(151, 13, 1) (151,)\n",
      "(3, 13, 1) (3,)\n",
      "Median Absolute Error (MAE): 0.0\n",
      "Mean Absolute Percentage Error (MAPE): 0.81 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.5 %\n"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/BTCUSDT_Binance_futures_data_day.csv\", \"sandevistan/BTC.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/ETHUSDT_Binance_futures_data_day.csv\", \"sandevistan/ETH.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/LTCUSDT_Binance_futures_data_day.csv\", \"sandevistan/LTC.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/LINKUSDT_Binance_futures_data_day.csv\", \"sandevistan/LINK.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/BNBUSDT_Binance_futures_data_day.csv\", \"sandevistan/BNB.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/XRPUSDT_Binance_futures_data_day.csv\", \"sandevistan/XRP.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/EOSUSDT_Binance_futures_data_day.csv\", \"sandevistan/EOS.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/TRXUSDT_Binance_futures_data_day.csv\", \"sandevistan/TRX.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/NEOUSDT_Binance_futures_data_day.csv\", \"sandevistan/NEO.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/ETCUSDT_Binance_futures_data_day.csv\", \"sandevistan/ETC.csv\")\n",
    "urllib.request.urlretrieve(\"https://www.cryptodatadownload.com/cdd/XLMUSDT_Binance_futures_data_day.csv\", \"sandevistan/XLM.csv\")\n",
    "\n",
    "df2 = [0] * 11\n",
    "\n",
    "df2[0]=pd.read_csv(\"sandevistan/BTC.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[1]=pd.read_csv(\"sandevistan/ETH.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[2]=pd.read_csv(\"sandevistan/LTC.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[3]=pd.read_csv(\"sandevistan/LINK.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[4]=pd.read_csv(\"sandevistan/BNB.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[5]=pd.read_csv(\"sandevistan/XRP.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[6]=pd.read_csv(\"sandevistan/EOS.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[7]=pd.read_csv(\"sandevistan/TRX.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[8]=pd.read_csv(\"sandevistan/NEO.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[9]=pd.read_csv(\"sandevistan/ETC.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "df2[10]=pd.read_csv(\"sandevistan/XLM.csv\", sep=r'\\s*,\\s*',header=0, encoding='ascii', engine='python',skiprows = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prediction(df,se):\n",
    "    df1= df[0:165]\n",
    "    df1=df1[::-1]\n",
    "\n",
    "    train_df = df1.filter(['close'])\n",
    "    data_unscaled = train_df.values\n",
    "\n",
    "    train_data_length = 161\n",
    "\n",
    "    mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    np_data = mmscaler.fit_transform(data_unscaled)\n",
    "    sequence_length = 13\n",
    "    predict_length=1\n",
    "    \n",
    "    index_Close = train_df.columns.get_loc(\"close\")\n",
    "    print(index_Close)\n",
    "\n",
    "    train_data_len = 161\n",
    "\n",
    "    train_data = np_data\n",
    "    test_data = np_data[train_data_len - sequence_length:, :]\n",
    "\n",
    "\n",
    "    def partition_dataset(sequence_length, train_df):\n",
    "        x, y = [], []\n",
    "        data_len = train_df.shape[0]\n",
    "        for i in range(sequence_length, data_len-predict_length):\n",
    "            x.append((train_df[i-sequence_length:i,:])+(train_df[i+predict_length]))\n",
    "            y.append(train_df[i+predict_length, index_Close]) \n",
    "\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        return x, y\n",
    "\n",
    "    x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "    x_test, y_test = partition_dataset(sequence_length, test_data)\n",
    "\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    print(x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "    def makemodels():\n",
    "\n",
    "        neurons=sequence_length\n",
    "        model2 = Sequential()\n",
    "        model2.add(Bidirectional(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], 1))))\n",
    "        model2.add(Bidirectional(LSTM(neurons, return_sequences=False)))\n",
    "        model2.add(Dense(26, activation='relu'))\n",
    "        model2.add(Dense(1))\n",
    "        model2.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "        return model2\n",
    "    \n",
    "    model=makemodels()\n",
    "\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=13, epochs=se,verbose=0)\n",
    "\n",
    "    y_pred_scaled = model.predict(x_test)\n",
    "    y_pred = mmscaler.inverse_transform(y_pred_scaled)\n",
    "    y_test_unscaled = mmscaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    MAE = mean_absolute_error(y_test_unscaled, y_pred)\n",
    "    print(f'Median Absolute Error (MAE): {np.round(MAE, 2)}')\n",
    "\n",
    "    MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "    print(f'Mean Absolute Percentage Error (MAPE): {np.round(MAPE, 2)} %')\n",
    "\n",
    "    MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled)) ) * 100\n",
    "    print(f'Median Absolute Percentage Error (MDAPE): {np.round(MDAPE, 2)} %')\n",
    "\n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    predval=[]\n",
    "\n",
    "    predval=predval+y_pred        \n",
    "\n",
    "    df55 = pd.DataFrame(data=(predval),columns=['Pred'])\n",
    "        \n",
    "    return df55;\n",
    "\n",
    "def kalkulator(predvidjeni,trenutni):\n",
    "    dfc=trenutni[0:1]\n",
    "\n",
    "    dfc['close']\n",
    "    total=sum(predvidjeni['Pred'])\n",
    "    average=total/len(predvidjeni)\n",
    "\n",
    "    odnosbtc= average/dfc['close']\n",
    "    odnosbtc= (average/dfc['close']-1)*100\n",
    "    return odnosbtc\n",
    "\n",
    "thisdict = [0]*11\n",
    "\n",
    "listaepoha=[105,65,105,105,105,105,105,105,78,105,105]\n",
    "\n",
    "for i in range(11):\n",
    "    dfka=df2[i][0:1]\n",
    "    predvidjeni=prediction(df2[i],listaepoha[i])\n",
    "    odnos=kalkulator(predvidjeni,df2[i])\n",
    "    thisdict[i]={\n",
    "        \"Sign\": dfka['symbol'],\n",
    "        \"Profit\" : odnos\n",
    "    }\n",
    "    \n",
    "    \n",
    "    stringara=\"\"\n",
    "\n",
    "for i in range(11):\n",
    "    isussveti=thisdict[i][\"Profit\"][0]\n",
    "    isussveti1=thisdict[i][\"Sign\"][0]\n",
    "\n",
    "    stringara += \"Kriptovaluta: \" + str(isussveti1)[0:3] + \" će u sledeca 2 dana da ima razliku od: \" +  str(isussveti)[0:5] +  \"\\n\" \n",
    "\n",
    "email_address = \"xsimostt@gmail.com\"\n",
    "\n",
    "email_password=\"frlqtrvjzdvgstkf\"\n",
    "\n",
    "# create email\n",
    "msg = EmailMessage()\n",
    "msg['Subject'] = \"Email subject\"\n",
    "msg['From'] = email_address\n",
    "msg['To'] = \"simkebiz@gmail.com\"\n",
    "msg.set_content(stringara)\n",
    "\n",
    "# send email\n",
    "with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
    "    smtp.login(email_address, email_password)\n",
    "    smtp.send_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d9f83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringara=\"\"\n",
    "\n",
    "for i in range(11):\n",
    "    isussveti=thisdict[i][\"Profit\"][0]\n",
    "    isussveti1=thisdict[i][\"Sign\"][0]\n",
    "\n",
    "    stringara += \"Kriptovaluta: \" + str(isussveti1)[0:3] + \" će u sledeca 2 dana da ima razliku od: \" +  str(isussveti)[0:5] +  \"\\n\" \n",
    "\n",
    "email_address = \"xsimostt@gmail.com\"\n",
    "\n",
    "email_password=\"frlqtrvjzdvgstkf\"\n",
    "\n",
    "# create email\n",
    "msg = EmailMessage()\n",
    "msg['Subject'] = \"Email subject\"\n",
    "msg['From'] = email_address\n",
    "msg['To'] = \"simkebiz@gmail.com\"\n",
    "msg.set_content(stringara)\n",
    "\n",
    "# send email\n",
    "with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
    "    smtp.login(email_address, email_password)\n",
    "    smtp.send_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ca376ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -4.079369\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03bded1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "# set your email and password\n",
    "# please use App Password\n",
    "email_address = \"xsimostt@gmail.com\"\n",
    "\n",
    "email_password=\"frlqtrvjzdvgstkf\"\n",
    "\n",
    "# create email\n",
    "msg = EmailMessage()\n",
    "msg['Subject'] = \"Email subject\"\n",
    "msg['From'] = email_address\n",
    "msg['To'] = \"simkebiz@gmail.com\"\n",
    "msg.set_content(\"This is eamil message\")\n",
    "\n",
    "# send email\n",
    "with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
    "    smtp.login(email_address, email_password)\n",
    "    smtp.send_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb6ea725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BTC/USDT'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisdict[0][\"Sign\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f632879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 29 20 31 45\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(now.year, now.month, now.day, now.hour, now.minute, now.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6470858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(now.hour=20 and now.minute=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
